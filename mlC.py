# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HIaWB-PM7rTZrVkSBmhkw1E-Faed6akM
"""

import streamlit as st
import pandas as pd
import numpy as np
import csv
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder
from sklearn.impute import SimpleImputer 

# Scikit-learn (Modelos de Clasificaci√≥n)
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
# from sklearn.neighbors import KNeighborsClassifier  <-- ELIMINADO
from sklearn.metrics import (
    accuracy_score,
    confusion_matrix,
    classification_report,
    roc_curve,
    auc,
)


# -----------------------------------------------------------
# FUNCI√ìN PARA CARGAR CSV Y DETECTAR DELIMITADOR AUTOM√ÅTICO
# -----------------------------------------------------------
def cargar_csv(uploaded_file):
    contenido = uploaded_file.read().decode('latin-1', errors='ignore')
    uploaded_file.seek(0)

    try:
        dialect = csv.Sniffer().sniff(contenido.splitlines()[0])
        sep = dialect.delimiter
    except:
        sep = ','  # Si no detecta, usamos coma por defecto

    df = pd.read_csv(uploaded_file, sep=sep, engine="python")
    df.columns = df.columns.str.strip()

    # Intentar convertir columnas a num√©ricas, manteniendo categ√≥ricas como strings si fallan
    for col in df.columns:
        df[col] = (
            df[col]
            .astype(str)
            .str.replace(",", "", regex=False)
            .str.strip()
        )
        # Intentar convertir a num√©rico, si falla, queda como string (categ√≥rica)
        df[col] = pd.to_numeric(df[col], errors='coerce').fillna(df[col])

    return df


# -----------------------------------------------------------
# M√âTRICAS DE CLASIFICACI√ìN
# -----------------------------------------------------------
def calculate_metrics_clf(y_true, y_pred, subset_name):
    return {
        'Conjunto': subset_name,
        'Accuracy': accuracy_score(y_true, y_pred),
        'Reporte_Clasificacion': classification_report(y_true, y_pred, output_dict=True, zero_division=0),
        'Matriz_Confusion': confusion_matrix(y_true, y_pred),
    }


# -----------------------------------------------------------
# INTERFAZ STREAMLIT
# -----------------------------------------------------------

st.set_page_config(page_title="Aplicaci√≥n Interactiva de Modelos de Clasificaci√≥n ML", layout="wide")

st.title("ü§ñ Aplicaci√≥n Interactiva de Modelos de Clasificaci√≥n")
st.markdown("---")

with st.sidebar:
    st.header("1. Cargar Datos CSV")
    uploaded_file = st.file_uploader("Seleccione archivo CSV", type=['csv'])

df = None
if uploaded_file:
    df = cargar_csv(uploaded_file)

    if df.shape[0] == 0:
        st.error("‚ö† El archivo se carg√≥ pero **no contiene filas v√°lidas**. Revisa el delimitador o el formato.")
        st.stop()
    else:
        st.success(f"‚úÖ Archivo cargado correctamente: {df.shape[0]} filas, {df.shape[1]} columnas.")
        st.dataframe(df.head())


if df is None:
    st.info("Por favor cargue un archivo CSV para continuar.")
    st.stop()


# Selecci√≥n de variables
with st.sidebar:
    st.header("2. Selecci√≥n de Variables")
    column_names = df.columns.tolist()

    selected_features = st.multiselect("Variables Independientes (X):", column_names, default=column_names[:-1])
    selected_target = st.selectbox("Variable Dependiente (Y - Categ√≥rica):", column_names, index=len(column_names)-1)

if selected_target in selected_features:
    st.error("‚ùå La variable Y no puede estar incluida en X.")
    st.stop()

# -------------------------------------------------
# PREPROCESAMIENTO ESPEC√çFICO PARA CLASIFICACI√ìN
# -------------------------------------------------

# 1. Transformaci√≥n de X: One-Hot Encoding para variables categ√≥ricas seleccionadas
X_data = df[selected_features].copy()
X_processed = pd.get_dummies(X_data, drop_first=True) 
X = X_processed.values

# MANEJO DE VALORES FALTANTES (NaN) EN X
# Aunque se quit√≥ KNN, la imputaci√≥n es una buena pr√°ctica general.
if np.isnan(X).any():
    st.sidebar.warning("‚ö†Ô∏è Detectados y rellenados valores NaN en las caracter√≠sticas (X) usando la media.")
    imputer = SimpleImputer(missing_values=np.nan, strategy='mean')
    X = imputer.fit_transform(X)


# 2. Transformaci√≥n de Y: Label Encoding para la variable objetivo (debe ser num√©rica)
try:
    le = LabelEncoder()
    y = le.fit_transform(df[selected_target].astype(str).fillna('Missing'))
    class_names = le.classes_
    st.sidebar.success(f"Y Categ√≥rica codificada: {selected_target} -> {len(class_names)} Clases.")
except Exception as e:
    st.error(f"‚ùå Error al codificar la variable objetivo (Y): {e}")
    st.stop()


if X.shape[0] < 5:
    st.error("‚ö† Se requieren al menos 5 observaciones para entrenar un modelo.")
    st.stop()

# Divisi√≥n en entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Selecci√≥n del modelo
with st.sidebar:
    st.header("3. Modelo de Clasificaci√≥n")
    models = {
        "Regresi√≥n Log√≠stica": LogisticRegression,
        "√Årbol de Decisi√≥n": DecisionTreeClassifier,
        "Random Forest": RandomForestClassifier,
        # "K-Vecinos Cercanos (KNN)": KNeighborsClassifier, <-- ELIMINADO del men√∫
        "M√°quinas de Soporte Vectorial (SVC)": SVC,
    }

    model_name = st.selectbox("Modelo:", list(models.keys()))

    # Par√°metros espec√≠ficos para Random Forest
    if model_name == "Random Forest":
        n_estimators = st.slider("N¬∞ de √°rboles:", 10, 300, 100)
        max_depth = st.slider("Profundidad m√°xima:", 2, 30, 10)
    
    # Par√°metros espec√≠ficos para SVC
    if model_name == "M√°quinas de Soporte Vectorial (SVC)":
        kernel = st.selectbox("Kernel:", ['rbf', 'linear', 'poly', 'sigmoid'])
        C = st.slider("Par√°metro C:", 0.1, 10.0, 1.0)
    
    # Se eliminaron los par√°metros espec√≠ficos para KNN aqu√≠


if st.sidebar.button("‚úÖ Entrenar Modelo"):
    model_class = models[model_name]

    # Inicializaci√≥n del modelo
    if model_name == "Random Forest":
        model = model_class(n_estimators=n_estimators, max_depth=max_depth, random_state=42)
    elif model_name == "M√°quinas de Soporte Vectorial (SVC)":
        # Nota: SVC por defecto no tiene predict_proba, lo que afectar√° la Curva ROC si no se a√±ade probability=True, pero lo dejamos simple.
        model = model_class(kernel=kernel, C=C, random_state=42)
    elif model_name == "Regresi√≥n Log√≠stica":
         model = model_class(max_iter=500, random_state=42)
    else:
        # Aqu√≠ tambi√©n se incluye DecisionTree y cualquier otro modelo simple
        model = model_class(random_state=42)
    
    # Entrenamiento
    model.fit(X_train, y_train)

    # Predicciones
    y_train_pred = model.predict(X_train)
    y_test_pred = model.predict(X_test)

    # C√°lculo de M√©tricas
    metrics_train = calculate_metrics_clf(y_train, y_train_pred, "Entrenamiento")
    metrics_test = calculate_metrics_clf(y_test, y_test_pred, "Validaci√≥n")

    st.header("üìä Resultados del Modelo de Clasificaci√≥n")

    # Presentaci√≥n de Accuracy
    st.markdown("### üéØ Precisi√≥n (Accuracy)")
    accuracy_df = pd.DataFrame({
        'Conjunto': ["Entrenamiento", "Validaci√≥n"],
        'Accuracy': [metrics_train['Accuracy'], metrics_test['Accuracy']]
    }).set_index('Conjunto')
    st.table(accuracy_df.style.format({'Accuracy': '{:.4f}'}))

    # Presentaci√≥n de Reporte de Clasificaci√≥n (Entrenamiento y Validaci√≥n)
    st.markdown("### üìã Reporte de Clasificaci√≥n")
    col_rep1, col_rep2 = st.columns(2)
    
    with col_rep1:
        st.subheader("Entrenamiento")
        report_df_train = pd.DataFrame(metrics_train['Reporte_Clasificacion']).transpose()
        st.dataframe(report_df_train.drop(columns=['support']).style.format('{:.2f}'))

    with col_rep2:
        st.subheader("Validaci√≥n")
        report_df_test = pd.DataFrame(metrics_test['Reporte_Clasificacion']).transpose()
        st.dataframe(report_df_test.drop(columns=['support']).style.format('{:.2f}'))
    
    # ---------------------------------------------
    # Gr√°ficos: Matriz de Confusi√≥n
    # ---------------------------------------------
    st.header("üìà Matriz de Confusi√≥n")
    st.markdown("> La Matriz de Confusi√≥n muestra cu√°ntas predicciones fueron correctas (diagonal principal) y cu√°ntas incorrectas.")
    
    col_cm1, col_cm2 = st.columns(2)

    # Matriz de Confusi√≥n (Entrenamiento)
    with col_cm1:
        st.subheader("Entrenamiento")
        cm_train = metrics_train['Matriz_Confusion']
        fig_cm_train, ax_cm_train = plt.subplots(figsize=(6, 6))
        sns.heatmap(cm_train, annot=True, fmt='d', cmap='Blues', cbar=False,
                    xticklabels=class_names, yticklabels=class_names, ax=ax_cm_train)
        ax_cm_train.set_ylabel('Valor Real')
        ax_cm_train.set_xlabel('Valor Predicho')
        ax_cm_train.set_title("Matriz de Confusi√≥n - Entrenamiento")
        st.pyplot(fig_cm_train)

    # Matriz de Confusi√≥n (Validaci√≥n)
    with col_cm2:
        st.subheader("Validaci√≥n")
        cm_test = metrics_test['Matriz_Confusion']
        fig_cm_test, ax_cm_test = plt.subplots(figsize=(6, 6))
        sns.heatmap(cm_test, annot=True, fmt='d', cmap='Greens', cbar=False,
                    xticklabels=class_names, yticklabels=class_names, ax=ax_cm_test)
        ax_cm_test.set_ylabel('Valor Real')
        ax_cm_test.set_xlabel('Valor Predicho')
        ax_cm_test.set_title("Matriz de Confusi√≥n - Validaci√≥n")
        st.pyplot(fig_cm_test)
        
    # Opcional: Curva ROC (solo para clasificaci√≥n binaria y modelos con predict_proba)
    if len(class_names) == 2 and hasattr(model, "predict_proba"):
        st.header("üìâ Curva ROC (Clasificaci√≥n Binaria)")
        
        # Predicciones de probabilidad
        y_score_train = model.predict_proba(X_train)[:, 1]
        y_score_test = model.predict_proba(X_test)[:, 1]
        
        # Calcular ROC
        fpr_train, tpr_train, _ = roc_curve(y_train, y_score_train)
        roc_auc_train = auc(fpr_train, tpr_train)
        fpr_test, tpr_test, _ = roc_curve(y_test, y_score_test)
        roc_auc_test = auc(fpr_test, tpr_test)
        
        # Gr√°fico ROC
        fig_roc, ax_roc = plt.subplots(figsize=(8, 6))
        ax_roc.plot(fpr_train, tpr_train, color='blue', lw=2, label=f'Entrenamiento (AUC = {roc_auc_train:.2f})')
        ax_roc.plot(fpr_test, tpr_test, color='green', lw=2, label=f'Validaci√≥n (AUC = {roc_auc_test:.2f})')
        ax_roc.plot([0, 1], [0, 1], color='red', lw=2, linestyle='--')
        ax_roc.set_xlim([0.0, 1.0])
        ax_roc.set_ylim([0.0, 1.05])
        ax_roc.set_xlabel('Tasa de Falsos Positivos (FPR)')
        ax_roc.set_ylabel('Tasa de Verdaderos Positivos (TPR)')
        ax_roc.set_title('Curva Caracter√≠stica de Operaci√≥n del Receptor (ROC)')
        ax_roc.legend(loc="lower right")
        st.pyplot(fig_roc)
